{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345f6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e93abc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b3800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f3c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"C:\\\\Users\\\\tusha\\\\Downloads\\\\AID710\\\\BC2\\\\RSNA_Crop\\\\BC2\"\n",
    "test_path=\"C:\\\\Users\\\\tusha\\\\Downloads\\\\AID710\\\\BC2\\\\RSNA_Crop\\\\test\"\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f58543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer', 'no_cancer']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7da642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e85ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1836d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1081c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e762b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.png'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ad0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 240\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(19.1554) Train Accuracy: 0.47625 Test Accuracy: 0.5041666666666667\n",
      "Epoch: 1 Train Loss: tensor(7.1144) Train Accuracy: 0.545 Test Accuracy: 0.5333333333333333\n",
      "Epoch: 2 Train Loss: tensor(4.3014) Train Accuracy: 0.61375 Test Accuracy: 0.4875\n",
      "Epoch: 3 Train Loss: tensor(2.1046) Train Accuracy: 0.69125 Test Accuracy: 0.4708333333333333\n",
      "Epoch: 4 Train Loss: tensor(0.8621) Train Accuracy: 0.77375 Test Accuracy: 0.4791666666666667\n",
      "Epoch: 5 Train Loss: tensor(1.5555) Train Accuracy: 0.73625 Test Accuracy: 0.5083333333333333\n",
      "Epoch: 6 Train Loss: tensor(0.8572) Train Accuracy: 0.805 Test Accuracy: 0.4708333333333333\n",
      "Epoch: 7 Train Loss: tensor(0.5187) Train Accuracy: 0.87625 Test Accuracy: 0.49166666666666664\n",
      "Epoch: 8 Train Loss: tensor(0.3032) Train Accuracy: 0.9075 Test Accuracy: 0.475\n",
      "Epoch: 9 Train Loss: tensor(0.2071) Train Accuracy: 0.935 Test Accuracy: 0.4708333333333333\n",
      "Epoch: 10 Train Loss: tensor(0.1555) Train Accuracy: 0.95125 Test Accuracy: 0.4666666666666667\n",
      "Epoch: 11 Train Loss: tensor(0.2047) Train Accuracy: 0.93875 Test Accuracy: 0.49583333333333335\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists for plotting\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "\n",
    "    # Save values for plotting\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    \n",
    "    # Save test accuracy for plotting\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) + ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plotting Train and Test accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(num_epochs), train_accuracy_list, label='Train Accuracy')\n",
    "plt.plot(range(num_epochs), test_accuracy_list, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Train loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(num_epochs), train_loss_list, label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25d652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
